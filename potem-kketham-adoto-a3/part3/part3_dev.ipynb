{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "allied-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "CHARACTER_WIDTH=14\n",
    "CHARACTER_HEIGHT=25\n",
    "\n",
    "\n",
    "def load_letters(fname):\n",
    "    im = Image.open(fname)\n",
    "    px = im.load()\n",
    "    (x_size, y_size) = im.size\n",
    "    print(im.size)\n",
    "    print(int(x_size / CHARACTER_WIDTH) * CHARACTER_WIDTH)\n",
    "    result = []\n",
    "    for x_beg in range(0, int(x_size / CHARACTER_WIDTH) * CHARACTER_WIDTH, CHARACTER_WIDTH):\n",
    "        result += [ [ \"\".join([ '*' if px[x, y] < 1 else ' ' for x in range(x_beg, x_beg+CHARACTER_WIDTH) ]) for y in range(0, CHARACTER_HEIGHT) ], ]\n",
    "    return result\n",
    "\n",
    "def load_training_letters(fname):\n",
    "    TRAIN_LETTERS=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789(),.-!?\\\"' \"\n",
    "    letter_images = load_letters(fname)\n",
    "    return { TRAIN_LETTERS[i]: letter_images[i] for i in range(0, len(TRAIN_LETTERS) ) }\n",
    "\n",
    "def get_training_arrays(letters):\n",
    "    #initialize array\n",
    "    arrays = {}\n",
    "    #for each letter in the train set\n",
    "    for letter in letters.keys():\n",
    "        #take each line of pixels, transla and add them to a 1d numpy array\n",
    "        arr = np.array([])\n",
    "        for line in letters[letter]:\n",
    "            arr = np.append(arr,np.array([1 if p == \"*\" else 0 for p in line]), axis = 0)\n",
    "        arrays[letter] = arr\n",
    "    \n",
    "    return arrays\n",
    "\n",
    "def get_test_array(letter):\n",
    "    #same process, add each line of pixels as a 1 or 0\n",
    "    array = np.array([])\n",
    "    for line in letter:\n",
    "        array = np.append(array, np.array([1 if p == \"*\" else 0 for p in line]), axis = 0)\n",
    "    \n",
    "    return array\n",
    "\n",
    "def get_class(train, test):\n",
    "    train_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789(),.-!?\\\"' \"\n",
    "    probs = np.array([])\n",
    "    for index, letter in enumerate(train.keys()):\n",
    "        matches = (test == train[letter]).sum()\n",
    "        mismatches = (CHARACTER_HEIGHT * CHARACTER_WIDTH) - (test == train[letter]).sum()\n",
    "        probs = np.append(probs, .99 * (matches / (CHARACTER_HEIGHT * CHARACTER_WIDTH)) + 0)\n",
    "        \n",
    "    best_match_ix = np.argmax(probs)\n",
    "    \n",
    "    return train_letters[best_match_ix]\n",
    "\n",
    "def simple_model(train_set, test_set):\n",
    "    prediction = \"\"\n",
    "    train_arrays = get_training_arrays(train_set)\n",
    "    for l in test_set:\n",
    "        test_array = get_test_array(l)\n",
    "        best_match = get_class(train_arrays, test_array)[0]\n",
    "        prediction += best_match\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def read_data(fname):\n",
    "    exemplars = []\n",
    "    file = open(fname, 'r');\n",
    "    for line in file:\n",
    "        data = [w for w in line.split()[0::2]]\n",
    "        exemplars += data\n",
    "\n",
    "    return exemplars\n",
    "\n",
    "def read_data2(fname):\n",
    "    exemplars = []\n",
    "    file = open(fname, 'r');\n",
    "    for line in file:\n",
    "        data = [w for w in line.split()]\n",
    "        exemplars += data\n",
    "\n",
    "    return exemplars\n",
    "\n",
    "def get_probs(txt):\n",
    "    train_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789(),.-!?\\\"' \"\n",
    "    sentences = []\n",
    "    sentence = \"\"\n",
    "    for word in txt:\n",
    "        if word == \".\":\n",
    "            sentence = sentence.rstrip()\n",
    "            sentence += word\n",
    "            sentences.append(sentence)\n",
    "            sentence = \"\"\n",
    "        elif word == ',':\n",
    "            sentence = sentence.rstrip()\n",
    "            sentence += word + \" \"\n",
    "        elif word == '``':\n",
    "            sentence += word\n",
    "        elif word == \"''\":\n",
    "            sentence = sentence.rstrip()\n",
    "            sentence += word + \" \"\n",
    "        elif word in ['The', 'the', \"It\", 'it']:\n",
    "            continue\n",
    "        else:\n",
    "            sentence += word + \" \"\n",
    "    lstr = \" \".join(sentences)\n",
    "    \n",
    "    #print(lstr[0:30])\n",
    "    \n",
    "    tr = {}\n",
    "    letter_counts = {}\n",
    "    for char in train_letters:\n",
    "        transitions = []\n",
    "        #for sentence in sentences:\n",
    "        for index, letter in enumerate(lstr):\n",
    "            if letter not in letter_counts.keys():\n",
    "                letter_counts[letter] = 1\n",
    "            letter_counts[letter] += 1\n",
    "            if index + 1 == len(lstr):\n",
    "                break\n",
    "            if letter == char:\n",
    "                transitions.append(lstr[index+1])\n",
    "        \n",
    "        trprobs = {}\n",
    "        for letter in transitions:\n",
    "            if letter not in trprobs.keys():\n",
    "                trprobs[letter] = transitions.count(letter)/len(transitions)#/letter_counts[letter]\n",
    "        tr[char] = trprobs\n",
    "    \n",
    "    init = {}\n",
    "    initials = []\n",
    "    for sentence in sentences:\n",
    "        initials.append(sentence[0])\n",
    "        \n",
    "    for letter in initials:\n",
    "        if letter not in init.keys():\n",
    "            init[letter] = initials.count(letter) / len(initials)\n",
    "    \n",
    "    return tr, init, letter_counts\n",
    "\n",
    "def get_test_arrays(letters):\n",
    "    arrays = {}\n",
    "    for letter in range(len(letters)):\n",
    "        arr = np.array([])\n",
    "        for line in letters[letter]:\n",
    "            arr = np.append(arr,np.array([1 if p == \"*\" else 0 for p in line]), axis = 0)\n",
    "        arrays[letter] = arr\n",
    "    \n",
    "    return arrays\n",
    "\n",
    "def viterbi(train_arrays, test_arrays, tr, init):\n",
    "    train_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789(),.-!?\\\"' \"\n",
    "    prediction = \"\"\n",
    "    t_min1= ()\n",
    "\n",
    "    for l in test_arrays:\n",
    "        if l == 0:\n",
    "            probs = np.array([])\n",
    "            for letter in train_letters:\n",
    "                pct_match = (test_arrays[0] == train_arrays[letter]).sum() / (CHARACTER_HEIGHT * CHARACTER_WIDTH)\n",
    "                matches = (test_arrays[0] == train_arrays[letter]).sum()\n",
    "                probs = np.append(probs, (.99 * pct_match*2) * init[letter] if letter in init.keys() else 1e-50)\n",
    "                #probs = np.append(probs, matches * init[letter] if letter in init.keys() else 1e-50)\n",
    "                print(\"Letter: \", letter, \"| Emission: \", (.98 * pct_match), \"| Initial Prob: \", init[letter] if letter in init.keys() else 1e-100)\n",
    "            \n",
    "            pred_letter = train_letters[np.argmax(probs)]\n",
    "            prediction += pred_letter\n",
    "            t_min1 = (pred_letter, np.max(probs))\n",
    "            print(t_min1)\n",
    "        else:    \n",
    "            probs = np.array([])\n",
    "            for letter in train_letters:\n",
    "                pct_match = (test_arrays[l] == train_arrays[letter]).sum() / (CHARACTER_HEIGHT * CHARACTER_WIDTH)\n",
    "                matches = (test_arrays[l] == train_arrays[letter]).sum()\n",
    "                probs = np.append(probs, t_min1[1] * (.99 * pct_match*2) * tr[t_min1[0]][letter] if letter in tr[t_min1[0]].keys() else 1e-50)\n",
    "                \n",
    "            pred_letter = train_letters[np.argmax(probs)]\n",
    "            prediction += pred_letter\n",
    "            t_min1 = (pred_letter, np.max(probs))\n",
    "            print(t_min1)\n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nasty-mechanism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.145"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8+.25) * .1-.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hispanic-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7+ .25) * .2-.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bacterial-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 25)\n",
      "1008\n",
      "(477, 25)\n",
      "476\n"
     ]
    }
   ],
   "source": [
    "txt = read_data('bc.train')\n",
    "train = load_training_letters('courier-train.png')\n",
    "test = load_letters('test-0-0.png')\n",
    "#test = load_letters('test-17-0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "offshore-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUPREME COURT OF THF UN1TED STATES'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "precise-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arrays = get_training_arrays(train)\n",
    "test_arrays = get_test_arrays(test)\n",
    "txt = read_data('12345.txt')\n",
    "tr, init, letter_counts = get_probs(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "designed-milton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': 0.6143170197224251,\n",
       " 'a': 0.041344046749452155,\n",
       " 'u': 0.025712198685171658,\n",
       " 'e': 0.05712198685171658,\n",
       " 'o': 0.10372534696859022,\n",
       " 'y': 0.002337472607742878,\n",
       " 'E': 0.00014609203798392987,\n",
       " 'w': 0.019138056975894813,\n",
       " 'r': 0.06267348429510591,\n",
       " 'O': 0.005113221329437546,\n",
       " '.': 0.007450693937180424,\n",
       " 'i': 0.028487947406866325,\n",
       " 'C': 0.0020452885317750183,\n",
       " 'N': 0.0005843681519357195,\n",
       " ' ': 0.007304601899196494,\n",
       " 's': 0.0027757487216946678,\n",
       " 'V': 0.008181154127100073,\n",
       " 'A': 0.002191380569758948,\n",
       " ',': 0.0014609203798392988,\n",
       " 'U': 0.001168736303871439,\n",
       " 'c': 0.0004382761139517896,\n",
       " \"'\": 0.00029218407596785974,\n",
       " 'R': 0.0010226442658875091,\n",
       " 'H': 0.0004382761139517896,\n",
       " '-': 0.00029218407596785974,\n",
       " 'S': 0.0030679327976625274,\n",
       " '}': 0.00014609203798392987,\n",
       " 'F': 0.0005843681519357195,\n",
       " 'P': 0.00029218407596785974,\n",
       " ')': 0.00014609203798392987}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "allied-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter:  A | Emission:  0.756 | Initial Prob:  0.09536541889483066\n",
      "Letter:  B | Emission:  0.8231999999999999 | Initial Prob:  0.046686589074132326\n",
      "Letter:  C | Emission:  0.8484 | Initial Prob:  0.020263185488098984\n",
      "Letter:  D | Emission:  0.84 | Initial Prob:  0.01774667086085771\n",
      "Letter:  E | Emission:  0.8092 | Initial Prob:  0.017196183286148685\n",
      "Letter:  F | Emission:  0.812 | Initial Prob:  0.031587501310684704\n",
      "Letter:  G | Emission:  0.8372 | Initial Prob:  0.008807801195344448\n",
      "Letter:  H | Emission:  0.8372 | Initial Prob:  0.0731624200482332\n",
      "Letter:  I | Emission:  0.8064 | Initial Prob:  0.08472265911712279\n",
      "Letter:  J | Emission:  0.8204 | Initial Prob:  0.0053475935828877\n",
      "Letter:  K | Emission:  0.7784 | Initial Prob:  0.002962147425815246\n",
      "Letter:  L | Emission:  0.7979999999999999 | Initial Prob:  0.013159274404949146\n",
      "Letter:  M | Emission:  0.7448 | Initial Prob:  0.033396246199014365\n",
      "Letter:  N | Emission:  0.7979999999999999 | Initial Prob:  0.02191464821222607\n",
      "Letter:  O | Emission:  0.8456 | Initial Prob:  0.03399916116179092\n",
      "Letter:  P | Emission:  0.7979999999999999 | Initial Prob:  0.02201950298836112\n",
      "Letter:  Q | Emission:  0.8092 | Initial Prob:  0.0007339834329453706\n",
      "Letter:  R | Emission:  0.7924 | Initial Prob:  0.013447625039320541\n",
      "Letter:  S | Emission:  0.9072 | Initial Prob:  0.05780119534444794\n",
      "Letter:  T | Emission:  0.7728 | Initial Prob:  0.11153926811366258\n",
      "Letter:  U | Emission:  0.8372 | Initial Prob:  0.007523330187690049\n",
      "Letter:  V | Emission:  0.7756000000000001 | Initial Prob:  0.003067002201950299\n",
      "Letter:  W | Emission:  0.7392000000000001 | Initial Prob:  0.05161476355247981\n",
      "Letter:  X | Emission:  0.756 | Initial Prob:  5.2427388067526476e-05\n",
      "Letter:  Y | Emission:  0.7924 | Initial Prob:  0.009358288770053475\n",
      "Letter:  Z | Emission:  0.8344 | Initial Prob:  7.864108210128971e-05\n",
      "Letter:  a | Emission:  0.8008000000000001 | Initial Prob:  0.007182552165251127\n",
      "Letter:  b | Emission:  0.7644 | Initial Prob:  0.0051640977246513575\n",
      "Letter:  c | Emission:  0.8231999999999999 | Initial Prob:  0.01190101709132851\n",
      "Letter:  d | Emission:  0.7896 | Initial Prob:  0.006736919366677152\n",
      "Letter:  e | Emission:  0.7784 | Initial Prob:  0.004928174478347489\n",
      "Letter:  f | Emission:  0.7812 | Initial Prob:  0.008912655971479501\n",
      "Letter:  g | Emission:  0.7644 | Initial Prob:  0.00372234455279438\n",
      "Letter:  h | Emission:  0.7756000000000001 | Initial Prob:  0.004430114291705987\n",
      "Letter:  i | Emission:  0.7867999999999999 | Initial Prob:  0.017379679144385027\n",
      "Letter:  j | Emission:  0.7335999999999999 | Initial Prob:  0.0008126245150466603\n",
      "Letter:  k | Emission:  0.7476 | Initial Prob:  0.0005242738806752647\n",
      "Letter:  l | Emission:  0.7784 | Initial Prob:  0.005137884030617595\n",
      "Letter:  m | Emission:  0.7392000000000001 | Initial Prob:  0.009961203732830031\n",
      "Letter:  n | Emission:  0.784 | Initial Prob:  0.0037747719408619063\n",
      "Letter:  o | Emission:  0.7979999999999999 | Initial Prob:  0.004639823843976093\n",
      "Letter:  p | Emission:  0.7364 | Initial Prob:  0.010485477613505295\n",
      "Letter:  q | Emission:  0.7504 | Initial Prob:  0.000655342350844081\n",
      "Letter:  r | Emission:  0.7979999999999999 | Initial Prob:  0.00825731362063542\n",
      "Letter:  s | Emission:  0.8064 | Initial Prob:  0.014365104330502254\n",
      "Letter:  t | Emission:  0.7784 | Initial Prob:  0.007051483695082311\n",
      "Letter:  u | Emission:  0.826 | Initial Prob:  0.0015203942539582678\n",
      "Letter:  v | Emission:  0.7812 | Initial Prob:  0.00186117227639719\n",
      "Letter:  w | Emission:  0.77 | Initial Prob:  0.015177728845548915\n",
      "Letter:  x | Emission:  0.77 | Initial Prob:  7.864108210128971e-05\n",
      "Letter:  y | Emission:  0.7252 | Initial Prob:  0.000655342350844081\n",
      "Letter:  z | Emission:  0.784 | Initial Prob:  1e-100\n",
      "Letter:  0 | Emission:  0.8148 | Initial Prob:  1e-100\n",
      "Letter:  1 | Emission:  0.812 | Initial Prob:  0.001756317500262137\n",
      "Letter:  2 | Emission:  0.8204 | Initial Prob:  0.0019922407465660062\n",
      "Letter:  3 | Emission:  0.8344 | Initial Prob:  0.0014679668658907413\n",
      "Letter:  4 | Emission:  0.7532 | Initial Prob:  0.00089126559714795\n",
      "Letter:  5 | Emission:  0.8148 | Initial Prob:  0.0006029149627765545\n",
      "Letter:  6 | Emission:  0.7979999999999999 | Initial Prob:  0.0003932054105064486\n",
      "Letter:  7 | Emission:  0.7867999999999999 | Initial Prob:  0.0004980601866415016\n",
      "Letter:  8 | Emission:  0.8315999999999999 | Initial Prob:  0.00023592324630386914\n",
      "Letter:  9 | Emission:  0.8036 | Initial Prob:  0.00015728216420257942\n",
      "Letter:  ( | Emission:  0.7784 | Initial Prob:  0.006500996120373283\n",
      "Letter:  ) | Emission:  0.7587999999999999 | Initial Prob:  0.003512635000524274\n",
      "Letter:  , | Emission:  0.8064 | Initial Prob:  5.2427388067526476e-05\n",
      "Letter:  . | Emission:  0.8288 | Initial Prob:  1e-100\n",
      "Letter:  - | Emission:  0.8036 | Initial Prob:  0.001205829925553109\n",
      "Letter:  ! | Emission:  0.8008000000000001 | Initial Prob:  1e-100\n",
      "Letter:  ? | Emission:  0.8372 | Initial Prob:  1e-100\n",
      "Letter:  \" | Emission:  0.8036 | Initial Prob:  1e-100\n",
      "Letter:  ' | Emission:  0.8204 | Initial Prob:  0.0015990353360595575\n",
      "Letter:    | Emission:  0.84 | Initial Prob:  1e-100\n",
      "('T', 0.17415422639644093)\n",
      "('h', 0.16946567404577093)\n",
      "('e', 0.06725167751995687)\n",
      "(' ', 0.023921425463032716)\n",
      "('a', 0.004110588205568701)\n",
      "('n', 0.0012468165726344977)\n",
      "(' ', 0.0004860955927570041)\n",
      "('a', 8.876909591640687e-05)\n",
      "('n', 2.5194378595798083e-05)\n",
      "(' ', 1.0093482505786858e-05)\n",
      "('a', 1.753635073348763e-06)\n",
      "('n', 5.35708940470864e-07)\n",
      "(' ', 2.1821904068688143e-07)\n",
      "('a', 3.998877593459326e-08)\n",
      "('n', 1.1219627485561145e-08)\n",
      "(' ', 4.464689573461744e-09)\n",
      "('a', 8.153261681220964e-10)\n",
      "('n', 2.269891339264792e-10)\n",
      "(' ', 8.727547482555001e-11)\n",
      "('a', 1.477580350862338e-11)\n",
      "('n', 4.545796713523282e-12)\n",
      "(' ', 1.8333795566702857e-12)\n",
      "('a', 3.2318024495951843e-13)\n",
      "('n', 9.417543804138348e-14)\n",
      "(' ', 3.8615228372200634e-14)\n",
      "('a', 6.635528578654615e-15)\n",
      "('n', 2.0054890283869368e-15)\n",
      "(' ', 9.382544949285282e-16)\n",
      "('a', 1.6658132436274923e-16)\n",
      "('n', 4.637671648944785e-17)\n",
      "(' ', 1.8205556875561247e-17)\n",
      "('a', 2.9783195977327937e-18)\n",
      "('n', 9.195105624569415e-19)\n",
      "(' ', 3.6343368041274647e-19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The an an an an an an an an an an '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi(train_arrays, test_arrays, tr, init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "#\n",
    "# Perform optical character recognition, usage:\n",
    "#     python3 ./image2text.py train-image-file.png train-text.txt test-image-file.png\n",
    "# \n",
    "# Authors: (insert names here)\n",
    "# (based on skeleton code by D. Crandall, Oct 2020)\n",
    "#\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import sys\n",
    "\n",
    "CHARACTER_WIDTH=14\n",
    "CHARACTER_HEIGHT=25\n",
    "\n",
    "\n",
    "def load_letters(fname):\n",
    "    im = Image.open(fname)\n",
    "    px = im.load()\n",
    "    (x_size, y_size) = im.size\n",
    "    print(im.size)\n",
    "    print(int(x_size / CHARACTER_WIDTH) * CHARACTER_WIDTH)\n",
    "    result = []\n",
    "    for x_beg in range(0, int(x_size / CHARACTER_WIDTH) * CHARACTER_WIDTH, CHARACTER_WIDTH):\n",
    "        result += [ [ \"\".join([ '*' if px[x, y] < 1 else ' ' for x in range(x_beg, x_beg+CHARACTER_WIDTH) ]) for y in range(0, CHARACTER_HEIGHT) ], ]\n",
    "    return result\n",
    "\n",
    "def load_training_letters(fname):\n",
    "    TRAIN_LETTERS=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789(),.-!?\\\"' \"\n",
    "    letter_images = load_letters(fname)\n",
    "    return { TRAIN_LETTERS[i]: letter_images[i] for i in range(0, len(TRAIN_LETTERS) ) }\n",
    "\n",
    "#####\n",
    "# main program\n",
    "if len(sys.argv) != 4:\n",
    "    raise Exception(\"Usage: python3 ./image2text.py train-image-file.png train-text.txt test-image-file.png\")\n",
    "\n",
    "(train_img_fname, train_txt_fname, test_img_fname) = sys.argv[1:]\n",
    "train_letters = load_training_letters(train_img_fname)\n",
    "test_letters = load_letters(test_img_fname)\n",
    "\n",
    "## Below is just some sample code to show you how the functions above work. \n",
    "# You can delete this and put your own code here!\n",
    "\n",
    "\n",
    "# Each training letter is now stored as a list of characters, where black\n",
    "#  dots are represented by *'s and white dots are spaces. For example,\n",
    "#  here's what \"a\" looks like:\n",
    "print(\"\\n\".join([ r for r in train_letters['a'] ]))\n",
    "\n",
    "# Same with test letters. Here's what the third letter of the test data\n",
    "#  looks like:\n",
    "print(\"\\n\".join([ r for r in test_letters[2] ]))\n",
    "\n",
    "\n",
    "\n",
    "# The final two lines of your output should look something like this:\n",
    "print(\"Simple: \" + \"Sample s1mple resu1t\")\n",
    "print(\"   HMM: \" + \"Sample simple result\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
